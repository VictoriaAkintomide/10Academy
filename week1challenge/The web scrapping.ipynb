{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import fire\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The web scrapping code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response(resp):\n",
    "                return resp.content  \n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0} : {1}'.format(url, str(e)))\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_good_response(resp):\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200 \n",
    "            and content_type is not None \n",
    "            and content_type.find('html') > -1)\n",
    "\n",
    "\n",
    "def log_error(e):\n",
    "\n",
    "    print(e)\n",
    "    \n",
    "def get_elements(url, tag='',search={}, fname=None):\n",
    "    \n",
    "    if isinstance(url,str):\n",
    "        response = simple_get(url)\n",
    "    else:\n",
    "        response = url\n",
    "\n",
    "    if response is not None:\n",
    "        html = BeautifulSoup(response, 'html.parser')\n",
    "        \n",
    "        res = []\n",
    "        if tag:    \n",
    "            for li in html.select(tag):\n",
    "                for name in li.text.split('\\n'):\n",
    "                    if len(name) > 0:\n",
    "                        res.append(name.strip())\n",
    "                       \n",
    "                \n",
    "        if search:\n",
    "            soup = html            \n",
    "            \n",
    "            \n",
    "            r = ''\n",
    "            if 'find' in search.keys():\n",
    "                print('findaing',search['find'])\n",
    "                soup = soup.find(**search['find'])\n",
    "                r = soup\n",
    "\n",
    "                \n",
    "            if 'find_all' in search.keys():\n",
    "                print('findaing all of',search['find_all'])\n",
    "                r = soup.find_all(**search['find_all'])\n",
    "   \n",
    "            if r:\n",
    "                for x in list(r):\n",
    "                    if len(x) > 0:\n",
    "                        res.extend(x)\n",
    "            \n",
    "        return res\n",
    "\n",
    "    \n",
    "    raise Exception('Error retrieving contents at {}'.format(url))    \n",
    "    \n",
    "    \n",
    "if get_ipython().__class__.__name__ == '__main__':\n",
    "    fire(get_tag_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the influencers twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://africafreak.com/100-most-influential-twitter-users-in-africa\"\n",
    "response = simple_get(url)\n",
    "res = get_elements(response, tag='h2')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "influencers = res[:len(res)-5]\n",
    "positions = []\n",
    "names = []\n",
    "handles = []\n",
    "\n",
    "influencer_split = [influencer.split(\"(\") for influencer in influencers]\n",
    "for i in range(len(influencer_split)):\n",
    "    id_name = influencer_split[i][0].split(\".\")\n",
    "    position = id_name[0]\n",
    "    fullname = id_name[1]\n",
    "    names.append(fullname)\n",
    "    positions.append(position)\n",
    "    handle = influencer_split[i][1]\n",
    "    handles.append(handle.replace(')',''))\n",
    "    \n",
    "positions = positions[::-1]\n",
    "names = names[::-1]\n",
    "handles = handles[::-1]\n",
    "\n",
    "influencers_list = pd.DataFrame({'position':positions, 'name':names, 'handle':handles})\n",
    "influencers_list.to_csv('100_influencers_africa.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assignnment 1: Top 10 Influencers in order of their priority\n",
    "top_10_african_influencers = influencers_list[:10]\n",
    "top_10_african_influencers.to_csv('10_african_influencers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the top african government officials twitter handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.atlanticcouncil.org/blogs/africasource/african-leaders-respond-to-coronavirus-on-twitter/#east-africa'\n",
    "response = simple_get(url)\n",
    "res_gov = get_elements(response, tag='blockquote')\n",
    "res_countries = get_elements(response, tag='strong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_countries = {'Botswana','Comoros','Lesotho','Madagascar','Mauritius','Mozambique','Ethiopia','Cameroon','Central African Republic','Congo-Brazzaville','Equatorial Guinea','São Tomé\\xa0and Príncipe','Liberia'} \n",
    "  \n",
    "countries = [country for country in res_countries if country not in unwanted_countries] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "for res in res_gov:\n",
    "    handle = re.findall(r\"@\\w+\", res)\n",
    "    if type(handle) is list:\n",
    "        hand = handle[-1]\n",
    "    handles.append(hand)\n",
    "    \n",
    "presidents_list = pd.DataFrame({'handles':handles, 'country':countries})\n",
    "presidents_list.to_csv('twitterhandles_africanpresidents.csv', index=False)\n",
    "#Assignment 2\n",
    "ten_presidents_list= presidents_list[:10]\n",
    "ten_presidents_list.to_csv('10_african_leaders.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
